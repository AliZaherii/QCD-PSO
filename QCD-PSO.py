# -*- coding: utf-8 -*-
"""Quantum.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11DnaG7xsYbpoLIQJ3sLSsaSNnPOoBg02
"""

!pip uninstall -y qiskit qiskit-aer
!pip install qiskit==0.39.0 qiskit-aer==0.11.0

!pip install pylatexenc

import os
os.environ['QISKIT_IN_COLAB'] = 'TRUE'

import qiskit
print(qiskit.__version__)

import numpy as np
import networkx as nx
import matplotlib.pyplot as plt
from qiskit import QuantumCircuit, Aer, execute
from qiskit.visualization import plot_histogram
import copy


def generate_random_graph(n_nodes, min_degree, max_degree):
    while True:
        # Generate random degrees for nodes
        degrees = np.random.randint(min_degree, max_degree + 1, size=n_nodes)

        # Ensure that each node has at least one edge
        degrees = np.maximum(degrees, 1)

        # Create an empty graph
        G = nx.Graph()
        G.add_nodes_from(range(n_nodes))

        # Create lists of nodes and degrees
        degree_list = [(i, d) for i, d in enumerate(degrees)]

        while degree_list:

            # Sort nodes based on degree
            degree_list.sort(key=lambda x: x[1], reverse=True)
            u, deg_u = degree_list.pop(0)
            if deg_u > 0:

                # Find nodes with remaining degree
                possible_nodes = [v for v, d in degree_list if d > 0 and v != u]
                if len(possible_nodes) >= deg_u:
                    for _ in range(deg_u):
                        v = possible_nodes.pop()
                        G.add_edge(u, v)
                        degree_list = [(x, d - (v == x)) for x, d in degree_list]
                        degree_list = [(x, d) for x, d in degree_list if d > 0]
                else:
                    break

        # Ensure that each node has at least one edge
        for node in range(n_nodes):
            if len(list(G.neighbors(node))) == 0:

                # Find other nodes to connect
                possible_nodes = [n for n in range(n_nodes) if n != node and len(list(G.neighbors(n))) > 0]
                if possible_nodes:
                    v = np.random.choice(possible_nodes)
                    G.add_edge(node, v)

        # Check graph connectivity
        if nx.is_connected(G) and len(G.edges) > 0:
            return G

# Calculate relative weights using AHP
def ahp_weights_F(matrix):
    eigvals, eigvecs = np.linalg.eig(matrix)
    max_index = np.argmax(eigvals)
    weights = np.abs(eigvecs[:, max_index])
    weights /= np.sum(weights)  # نرمال‌سازی
    return weights


def generate_random_ahp_matrix(size=4):
    matrix = np.random.rand(size, size)
    for i in range(size):
        for j in range(size):
            if i == j:
                matrix[i, j] = 1
            elif i < j:
                matrix[i, j] = np.random.uniform(0.1, 9)  # مقادیر رندم بین 0.1 تا 9
                matrix[j, i] = 1 / matrix[i, j]
    return matrix


# Define quantitative and qualitative features
def calculate_features(ahp_weights, distance, snr, reliability, latency, throughput, error_rate):
    signal_speed = 3e8  # Signal speed (e.g., speed of light in meters per second)
    bandwidth = 1e6  # Bandwidth in Hertz
    delay = distance / signal_speed
    capacity = bandwidth * np.log2(1 + snr)
    quality = (ahp_weights[0] * reliability +
               ahp_weights[1] * (1 / latency) +
               ahp_weights[2] * throughput +
               ahp_weights[3] * (1 - error_rate))
    return delay, capacity, quality

def assign_edge_features(G, ahp_weights):
    edge_list = []
    for (u, v) in G.edges():
        distance = np.random.uniform(100, 1000)  # In meters
        snr = np.random.uniform(1, 20)
        reliability = np.random.uniform(0.8, 1.0)
        latency = np.random.uniform(0.1, 1.0)  # In seconds
        throughput = np.random.uniform(1, 10)
        error_rate = np.random.uniform(0, 0.1)
        delay, capacity, quality = calculate_features(ahp_weights, distance, snr, reliability, latency, throughput, error_rate)
        G[u][v]['delay'] = delay
        G[u][v]['capacity'] = capacity
        G[u][v]['quality'] = quality
        G[u][v]['error_rate'] = error_rate
        edge_list.append((u, v))  # Store edges
    return G, edge_list


def topsis_weights(G, ahp_weights):
    # Create decision matrix
    decision_matrix = np.array([
        [attr['delay'] for u, v, attr in G.edges(data=True)],
        [attr['capacity'] for u, v, attr in G.edges(data=True)],
        [attr['quality'] for u, v, attr in G.edges(data=True)],
        [attr['error_rate'] for u, v, attr in G.edges(data=True)]
    ]).T

    # Normalize decision matrix
    norm_matrix = decision_matrix / np.sqrt(np.sum(decision_matrix ** 2, axis=0, keepdims=True))
    # Apply weights to the final matrix
    weighted_matrix = norm_matrix * ahp_weights
    # Calculate the best and worst ideal solutions
    ideal_best = np.max(weighted_matrix, axis=0)
    ideal_worst = np.min(weighted_matrix, axis=0)
    # Calculate the distances
    distance_best = np.sqrt(np.sum((weighted_matrix - ideal_best) ** 2, axis=1))
    distance_worst = np.sqrt(np.sum((weighted_matrix - ideal_worst) ** 2, axis=1))
    # Calculate TOPSIS scores
    topsis_score = distance_worst / (distance_best + distance_worst)


    all_edges = [(i, j) for i in G.nodes for j in G.nodes if i < j]  # همه یال‌های ممکن
    topsis_score_final = np.zeros(len(all_edges))

    for i,(u, v) in enumerate(G.edges()):
        for j,edge in enumerate(all_edges):
          if(edge==(u, v)):
            topsis_score_final[j] = topsis_score[i]

    return topsis_score_final


def create_quantum_circuit_from_edges(edge_list, topsis_scores):
    n_qubits = max(max(edge) for edge in edge_list) + 1
    qcircuit = QuantumCircuit(n_qubits)

    for edge, score in zip(edge_list, topsis_scores):
        qubit1, qubit2 = edge

        if score > 0.85:
            # Use basic and simple gates to reduce circuit depth, without using T gates
            qcircuit.h(qubit1)
            qcircuit.cx(qubit1, qubit2)  # Use a simple CX gate
            qcircuit.id(qubit2)  # Add identity (Identity) to avoid additional depth

        elif score > 0.7:
            # Use simple gates with low depth and limited use of two-qubit gates, without T gates
            qcircuit.rx(np.pi / 6, qubit1)  # Reduce angle to decrease depth
            qcircuit.cx(qubit1, qubit2)
            qcircuit.id(qubit1)  # Add identity to prevent extra depth

        elif score > 0.5:
            # Use slightly more complex gates, but still with moderate depth and minimal use of T gates
            qcircuit.rx(np.pi / 4, qubit1)
            qcircuit.ry(np.pi / 4, qubit2)
            qcircuit.cx(qubit1, qubit2)
            qcircuit.t(qubit2)  # Use only one T gate to reduce depth

        elif score > 0.3:
            # Increase use of T gates and more complex gates for lower scores
            qcircuit.ry(np.pi / 2, qubit1)
            qcircuit.rz(np.pi / 2, qubit2)
            qcircuit.cz(qubit1, qubit2)
            qcircuit.t(qubit1)
            qcircuit.t(qubit2)

        else:
            # Extensive use of T gates and more complex gates for very low scores
            qcircuit.u3(np.pi / 4, np.pi / 4, np.pi / 4, qubit1)
            qcircuit.u3(np.pi / 3, np.pi / 4, np.pi / 4, qubit2)
            qcircuit.crx(np.pi / 4, qubit1, qubit2)
            qcircuit.cu3(np.pi / 2, np.pi / 4, np.pi / 4, qubit1, qubit2)
            qcircuit.t(qubit1)
            qcircuit.t(qubit2)
            qcircuit.t(qubit1)  # Adding an extra T gate for the first qubit
            qcircuit.t(qubit2)  # Adding an extra T gate for the second qubit

    return qcircuit


def create_initial_population(n_qbit, population_size):
    population = []

    edge_lists=[]
    for _ in range(population_size):
        comparison_matrix =generate_random_ahp_matrix()
        ahp_weights = ahp_weights_F(comparison_matrix)
        print("AHP Weights:", ahp_weights)
        G = generate_random_graph(n_qbit, min_degree=1, max_degree=4)
        G, edge_list = assign_edge_features(G, ahp_weights)
        edge_lists.append(edge_list)
        all_edges = [(i, j) for i in G.nodes for j in G.nodes if i < j]
        topsis_scores = topsis_weights(G, ahp_weights)
        print("TOPSIS Scores:", topsis_scores)
        features = topsis_scores
        qcircuit = create_quantum_circuit_from_edges(edge_list, features)
        population.append((qcircuit, features))

    return population, all_edges


def calculate_circuit_depth(circuit):
    return circuit.depth()


def count_t_gates(circuit):
    # Counting the number of T gates in the circuit
    return sum(1 for gate in circuit.data if gate[0].name == 't')

def evaluate_reproducibility(qcircuit, shots=1024):
    qcircuit.measure_all()
    qasm_simulator = Aer.get_backend('qasm_simulator')
    results = [execute(qcircuit, qasm_simulator, shots=shots).result().get_counts() for _ in range(10)]
    all_counts = {}
    for result in results:
        for key, value in result.items():
            if key in all_counts:
                all_counts[key] += value
            else:
                all_counts[key] = value
    probabilities = [count / (shots * len(results)) for count in all_counts.values()]
    variance = np.var(probabilities)
    return variance


def evaluate_population(qcircuit, depth_weight=0.4,
                        reproducibility_weight=0.1,
                        t_gate_weight=0.5):
    depth = calculate_circuit_depth(qcircuit)
    reproducibility = evaluate_reproducibility(qcircuit)
    max_depth=40
    t_gate_count = count_t_gates(qcircuit)
    normalized_depth = (max_depth - depth) / (max_depth - 1)
    normalized_reproducibility = 1 / (1 + reproducibility)
    normalized_t_gates = 1 / (1 + t_gate_count)

    print("Depth:", depth)
    print("normalized_reproducibility:", normalized_reproducibility)
    print("t_gate_count:", t_gate_count)

    combined_score = (normalized_depth * depth_weight +
                      normalized_reproducibility * reproducibility_weight +
                      normalized_t_gates * t_gate_weight)

    return np.array(combined_score)

# Quantum Circuit Design with Particle Swarm Optimization (QCD-PSO)
def QCD_particle_swarm_optimization(n_qbit, population_particle, population_size, all_edges, iterations, w, c1, c2):
    population_particle = copy.deepcopy(population)
    print("*************************************")
    velocities = [np.random.uniform(-1, 1, len(population_particle[i][1])) for i in range(population_size)]
    personal_best_positions = [features for _, features in population_particle]
    personal_best_score = [evaluate_population(circuit) for circuit, _ in population_particle]
    global_best_index = np.argmax(personal_best_score)
    global_best_position = personal_best_positions[global_best_index]
    global_best_scores = [personal_best_score[global_best_index]]
    signal_speed = 3e8
    bandwidth = 1e6

    for iter in range(iterations):
        for i in range(population_size):

            comparison_matrix =generate_random_ahp_matrix()
            ahp_weights = ahp_weights_F(comparison_matrix)
            distance = np.random.uniform(100, 1000)
            snr = np.random.uniform(1, 20)
            reliability = np.random.uniform(0.8, 1.0)
            latency = np.random.uniform(0.1, 1.0)
            throughput = np.random.uniform(1, 10)

            error_rate = np.random.uniform(0, 0.1)
            delay = distance / signal_speed
            capacity = bandwidth * np.log2(1 + snr)
            quality = (ahp_weights[0] * reliability +
                      ahp_weights[1] * (1 / latency) +
                      ahp_weights[2] * throughput +
                      ahp_weights[3] * (1 - error_rate))

            # Normalizing parameters
            max_capacity = 1e8  # Maximum value for capacity
            min_capacity = 1e6  # Minimum value for capacity
            normalized_capacity = (capacity - min_capacity) / (max_capacity - min_capacity)

            # Combining parameters to affect speed
            normalized_quality = (quality - 0) / (10 - 0)  # Normalizing quality (assumed)
            normalized_delay = (delay - 0) / (1 - 0)  # Normalizing delay (assumed)
            normalized_error_rate = (error_rate - 0) / (0.1 - 0)  # Normalizing error rate (assumed)

            # Calculating the weighting factor
            quality_delay_factor = 1 + 0.1 * (normalized_quality - normalized_delay)
            capacity_factor = 1 + 0.1 * (normalized_capacity - 0.5)
            error_rate_factor = 1 - normalized_error_rate

            # Updating speed
            r1, r2 = np.random.rand(len(population_particle[i][1])), np.random.rand(len(population_particle[i][1]))
            velocities[i] = (w * velocities[i] +
                             c1 * r1 * (personal_best_positions[i] - population_particle[i][1]) +
                             c2 * r2 * (global_best_position - population_particle[i][1])) * (quality_delay_factor + capacity_factor + error_rate_factor)

            velocities[i] = np.clip(velocities[i], -1, 1)  # تغییر محدوده کلپینگ
            new_features = population_particle[i][1] + velocities[i]
            new_features = np.clip(new_features, 0, 1)

            edge_lists = []
            for j in range(len(new_features)):
                if new_features[j] != 0:
                    edge_lists.append(all_edges[j])

            if len(edge_lists)==0:
              new_qcircuit=population_particle[i][0]
              new_features=population_particle[i][1]
            else:
              new_qcircuit = create_quantum_circuit_from_edges(edge_lists, new_features)

            population_particle[i] = (new_qcircuit, new_features)
            score = evaluate_population(new_qcircuit)
            print("Score:", score)
            print("*************************************************")
            if score > personal_best_score[i]:
                personal_best_positions[i] = new_features
                personal_best_score[i] = score
                if score > personal_best_score[global_best_index]:
                    global_best_index = i
                    global_best_position = new_features

        global_best_scores.append(personal_best_score[global_best_index])

    optimized_circuit = create_quantum_circuit_from_edges(edge_lists, personal_best_positions[global_best_index])
    plt.plot(global_best_scores, label='QCD-PSO')
    plt.xlabel('Iteration')
    plt.ylabel('Global Best Score')
    plt.title('Global Optimization Plot')
    plt.grid(True)

    return optimized_circuit, global_best_scores,global_best_index



# Parameters
population_size = 30
iterations = 100
w = 0.5
c1 = 2
c2 = 2
n_qbit = 5


main_circuit=[]
print("Initial Population:")
population, all_edges = create_initial_population(n_qbit, population_size)
for i in range(population_size):
    main_circuit.append(population[i][0])

# Execute Algorithm
optimized_circuit_QCD_pso, global_best_scores_QCD_pso, global_best_index_QCD_pso = QCD_particle_swarm_optimization(n_qbit,population, population_size,all_edges, iterations, w, c1, c2)

print(f"The main depth of the {global_best_index_QCD_pso}-th quantum circuit is {main_circuit[global_best_index_QCD_pso].depth()}.")
print(f"The optimized depth of the {global_best_index_QCD_pso}-th quantum circuit is {optimized_circuit_QCD_pso.depth()}.")

print("Optimized Quantum Circuits:")
print(optimized_circuit_pso)

